{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bc001a-d4e1-44ea-a19d-cc61d3d00479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldhu\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe75be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aldhu\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197c3f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "dataset_original = pd.read_csv(\"PotentialTalents.csv\")\n",
    "print(\"Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11a9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting & Cleaning the dataset\n",
    "dataset_cleaned_temp = dataset_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a522ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "job_title       0\n",
      "location        0\n",
      "connection      0\n",
      "fit           104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking missing data\n",
    "print(dataset_cleaned_temp.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0bb68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking duplicates\n",
    "print(dataset_cleaned_temp.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383e6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary words & Replace abbreviations\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n",
    "abbreviations_to_replace = {\n",
    "    'GPHR': 'Global Professional in Human Resources',\n",
    "    'CSR': 'Corporate Social Responsibility',\n",
    "    'MES': 'Manufacturing Execution Systems',\n",
    "    'SPHR': 'Senior Professional in Human Resources',\n",
    "    'SVP': 'Senior Vice President',\n",
    "    'GIS': 'Geographic Information System',\n",
    "    'RRP': 'Reduced Risk Products',\n",
    "    'CHRO': 'Chief Human Resources Officer',\n",
    "    'HRIS': 'Human resources information system',\n",
    "    'HR': 'Human resources',\n",
    "}\n",
    "\n",
    "def replace_abbreviations(sentence):\n",
    "    replaced_sentence = sentence\n",
    "    for abbreviation, replacement in abbreviations_to_replace.items():\n",
    "        pattern = r'\\b{}\\b'.format(re.escape(abbreviation))\n",
    "        replaced_sentence = re.sub(pattern, replacement, replaced_sentence, flags=re.IGNORECASE)\n",
    "    return replaced_sentence\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    new_sentence = re.sub(r'[+*,.|(){}&\\-\\']', '', sentence)\n",
    "    new_sentence = replace_abbreviations(new_sentence)\n",
    "    words = new_sentence.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lemmatized_sentence = \" \".join([token.lemma_ for token in spacy_nlp(\" \".join(stemmed_words)) if not token.is_stop])\n",
    "    return lemmatized_sentence\n",
    "\n",
    "dataset_cleaned_temp['job_title_cleaned'] = dataset_cleaned_temp['job_title'].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b2036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "dataset_preprocessed = dataset_cleaned_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ddc62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aldhu\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Setup BERT & Utils\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def get_bert_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        encoded_inputs = bert_tokenizer(sentence, padding=True, truncation=True, return_tensors='tf')\n",
    "        outputs = bert_model(encoded_inputs)\n",
    "        embeddings.append(tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy().reshape(-1))\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e99c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Doc2Vec\n",
    "tagged_data = [TaggedDocument(words=clean_sentence(job_title).split(), tags=[str(i)]) for i, job_title in enumerate(dataset_preprocessed['job_title_cleaned'])]\n",
    "doc2vec_model = Doc2Vec(vector_size=768, window=2, min_count=1, workers=4, epochs=40)\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "def get_doc2vec_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        embeddings.append(doc2vec_model.infer_vector(sentence.split()))\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b51dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and get similarity\n",
    "def encode_and_get_similarity(data, queries, search_columns, output_columns):\n",
    "    data = data.copy()\n",
    "    bert_embeddings = {}\n",
    "    doc2vec_embeddings = {}\n",
    "    queries_embeddings = []\n",
    "    doc2vec_queries_embeddings = []\n",
    "\n",
    "    for index, query in enumerate(queries):\n",
    "        query_cleaned = replace_abbreviations(query)\n",
    "        query_cleaned = clean_sentence(query_cleaned)\n",
    "        queries_embeddings.append(get_bert_embeddings([query_cleaned]))\n",
    "        doc2vec_queries_embeddings.append(get_doc2vec_embeddings([query_cleaned]))\n",
    "\n",
    "    queries_embeddings_mean = np.mean(queries_embeddings, axis=0)\n",
    "    doc2vec_queries_embeddings_mean = np.mean(doc2vec_queries_embeddings, axis=0)\n",
    "\n",
    "    for index, column in enumerate(search_columns):\n",
    "        sentences = data[column].tolist()\n",
    "        bert_embeddings[column] = get_bert_embeddings(sentences)\n",
    "        doc2vec_embeddings[column] = get_doc2vec_embeddings(sentences)\n",
    "        \n",
    "        bert_cosine_similarities = cosine_similarity(queries_embeddings_mean, bert_embeddings[column])\n",
    "        doc2vec_cosine_similarities = cosine_similarity(doc2vec_queries_embeddings_mean, doc2vec_embeddings[column])\n",
    "        \n",
    "        print(f\"BERT similarities shape: {bert_cosine_similarities.shape}\")\n",
    "        print(f\"Doc2Vec similarities shape: {doc2vec_cosine_similarities.shape}\")\n",
    "\n",
    "        if len(output_columns) > 0:\n",
    "            data[output_columns[0]] = bert_cosine_similarities[0]\n",
    "        if len(output_columns) > 1:\n",
    "            data[output_columns[1]] = doc2vec_cosine_similarities[0]\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f7194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search queries/keywords\n",
    "queries = [\n",
    "    'aspiring human resources',\n",
    "    'seeking human resources'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a9fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT similarities shape: (1, 104)\n",
      "Doc2Vec similarities shape: (1, 104)\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings & similarities\n",
    "dataset_preprocessed = encode_and_get_similarity(dataset_preprocessed, queries, ['job_title_cleaned'], ['bert_similarity', 'doc2vec_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c30fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of BERT and Doc2Vec similarities\n",
    "dataset_preprocessed['mean_score'] = dataset_preprocessed[['bert_similarity', 'doc2vec_similarity']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9450d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe based on the new mean_score in descending order\n",
    "dataset_preprocessed = dataset_preprocessed.sort_values(by='mean_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eadf930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Candidates based on BERT Similarity:\n",
      "                                             job_title  bert_similarity\n",
      "59                 Aspiring Human Resources Specialist         0.918639\n",
      "48                 Aspiring Human Resources Specialist         0.918639\n",
      "23                 Aspiring Human Resources Specialist         0.918639\n",
      "35                 Aspiring Human Resources Specialist         0.918639\n",
      "5                  Aspiring Human Resources Specialist         0.918639\n",
      "98                    Seeking Human Resources Position         0.899538\n",
      "67             Human Resources Specialist at Luxottica         0.890844\n",
      "87                    Human Resources Management Major         0.883634\n",
      "100              Human Resources Generalist at Loparex         0.867990\n",
      "20               Aspiring Human Resources Professional         0.860986\n",
      "2                Aspiring Human Resources Professional         0.860986\n",
      "32               Aspiring Human Resources Professional         0.860986\n",
      "57               Aspiring Human Resources Professional         0.860986\n",
      "16               Aspiring Human Resources Professional         0.860986\n",
      "45               Aspiring Human Resources Professional         0.860986\n",
      "96               Aspiring Human Resources Professional         0.860986\n",
      "88                     Director Human Resources  at EY         0.845359\n",
      "81   Aspiring Human Resources Professional | An ene...         0.839728\n",
      "7                                 HR Senior Specialist         0.837753\n",
      "60                                HR Senior Specialist         0.837753\n",
      "\n",
      "Top 20 Candidates based on Doc2Vec Similarity:\n",
      "                                             job_title  doc2vec_similarity\n",
      "83   Human Resources professional for the world lea...            0.970110\n",
      "89   Undergraduate Research Assistant at Styczynski...            0.970104\n",
      "86   Bachelor of Science in Biology from Victoria U...            0.970046\n",
      "90        Lead Official at Western Illinois University            0.970032\n",
      "101   Business Intelligence and Analytics at Travelers            0.970010\n",
      "95   Student at Indiana University Kokomo - Busines...            0.969986\n",
      "91   Seeking employment opportunities within Custom...            0.969975\n",
      "103   Director Of Administration at Excellence Logging            0.969970\n",
      "84   RRP Brand Portfolio Executive at JTI (Japan To...            0.969947\n",
      "85   Information Systems Specialist and Programmer ...            0.969936\n",
      "70     Human Resources Generalist at ScottMadden, Inc.            0.969927\n",
      "74   Nortia Staffing is seeking Human Resources, Pa...            0.969925\n",
      "93   Seeking Human  Resources Opportunities. Open t...            0.969924\n",
      "11   SVP, CHRO, Marketing & Communications, CSR Off...            0.969913\n",
      "30   2019 C.T. Bauer College of Business Graduate (...            0.969912\n",
      "92   Admissions Representative at Community medical...            0.969906\n",
      "41   SVP, CHRO, Marketing & Communications, CSR Off...            0.969906\n",
      "63   SVP, CHRO, Marketing & Communications, CSR Off...            0.969903\n",
      "54   SVP, CHRO, Marketing & Communications, CSR Off...            0.969900\n",
      "75   Aspiring Human Resources Professional | Passio...            0.969898\n"
     ]
    }
   ],
   "source": [
    "# First Rank for BERT and Doc2Vec using mean_score\n",
    "first_rank_bert = dataset_preprocessed.sort_values(by='bert_similarity', ascending=False).head(20)\n",
    "first_rank_doc2vec = dataset_preprocessed.sort_values(by='doc2vec_similarity', ascending=False).head(20)\n",
    "\n",
    "# Print the initial rankings\n",
    "print(\"Top 20 Candidates based on BERT Similarity:\")\n",
    "print(first_rank_bert[['job_title', 'bert_similarity']])\n",
    "\n",
    "print(\"\\nTop 20 Candidates based on Doc2Vec Similarity:\")\n",
    "print(first_rank_doc2vec[['job_title', 'doc2vec_similarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starred Candidates\n",
    "# Marking them as favorite/bookmark\n",
    "starred_ids = [int(item) for item in input(\"Enter the ids of the candidates you want to star (separate by spaces): \").split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78325519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Rank (Re-Rank)\n",
    "dataset_preprocessed.loc[dataset_preprocessed['id'].isin(starred_ids), 'is_starred'] = 1\n",
    "dataset_preprocessed.loc[~dataset_preprocessed['id'].isin(starred_ids), 'is_starred'] = 0\n",
    "\n",
    "def get_starred_score(data):\n",
    "    data = data.copy()\n",
    "    queries = data[data['is_starred'] == 1]['job_title_cleaned']\n",
    "    similarities = []\n",
    "    for query in queries:\n",
    "        print('START: ' + query)\n",
    "        data = encode_and_get_similarity(data, [query], ['job_title_cleaned'], ['starred_similarity'])\n",
    "        if 'starred_similarity' in data.columns:\n",
    "            similarities.append(data['starred_similarity'])\n",
    "        else:\n",
    "            print(\"Column 'starred_similarity' not found in data.\")\n",
    "        \n",
    "    if len(similarities) > 0:\n",
    "        starred_similarity = np.mean(similarities, axis=0)\n",
    "    else:\n",
    "        starred_similarity = np.zeros(len(data))\n",
    "    \n",
    "    return starred_similarity\n",
    "\n",
    "dataset_preprocessed['starred_similarity'] = get_starred_score(dataset_preprocessed)\n",
    "dataset_preprocessed['mean_similarity_bert'] = dataset_preprocessed[['bert_similarity', 'starred_similarity']].mean(axis=1)\n",
    "dataset_preprocessed['mean_similarity_doc2vec'] = dataset_preprocessed[['doc2vec_similarity', 'starred_similarity']].mean(axis=1)\n",
    "\n",
    "final_rank_bert = dataset_preprocessed[['job_title', 'is_starred', 'bert_similarity', 'starred_similarity', 'mean_similarity_bert']].sort_values(by=['mean_similarity_bert', 'is_starred'], ascending=False).head(20)\n",
    "final_rank_doc2vec = dataset_preprocessed[['job_title', 'is_starred', 'doc2vec_similarity', 'starred_similarity', 'mean_similarity_doc2vec']].sort_values(by=['mean_similarity_doc2vec', 'is_starred'], ascending=False).head(20)\n",
    "\n",
    "print(\"Final Rank using BERT embeddings:\")\n",
    "print(final_rank_bert)\n",
    "\n",
    "print(\"Final Rank using Doc2Vec embeddings:\")\n",
    "print(final_rank_doc2vec)\n",
    "\n",
    "print(\"Top candidates sorted by mean similarity score:\")\n",
    "print(dataset_preprocessed[['job_title', 'bert_similarity', 'doc2vec_similarity', 'mean_score']].head(20))  # Display top sorted candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df59cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
